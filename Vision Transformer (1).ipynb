{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44a0a03-05e3-4249-8212-57f2f354074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a698fb3-ce57-487f-a92d-85c75ec6507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482fc30f-6c44-4cd4-86a0-fec02edee54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d101013e-340d-406e-b589-3bf2c3dbbafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Paramters\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "image_size = 72\n",
    "patch_size = 6\n",
    "num_patch = (image_size // patch_size)**2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transfomer_units = [projection_dim * 2, projection_dim]\n",
    "transformer_layers = 8\n",
    "mlp_heads_unit = [2048,1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf4a2053-08b0-4c79-9612-2d30bb9e633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Patches layer\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID'\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345d6b9c-a4c1-4224-9e6c-405cb0de1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch Encoder layer\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
    "\n",
    "    def call(self, patches):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13a7abb6-3217-431f-bef5-7e59606ad477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(image_size=32, patch_size=4, num_patches=64, projection_dim=64,\n",
    "                          num_heads=4, transformer_layers=8, transformer_units=[128, 64], mlp_units=[2048, 1024], num_classes=10):\n",
    "\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
    "\n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "\n",
    "    # Encode patches\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple transformer layers\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "        # Create a multi-head attention layer\n",
    "        attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim, dropout=0.1)(x1, x1)\n",
    "\n",
    "        # Skip connection 1\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer normalization 2\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "        # MLP\n",
    "        x3 = layers.Dense(transformer_units[0], activation=tf.nn.gelu)(x3)\n",
    "        x3 = layers.Dense(transformer_units[1], activation=tf.nn.gelu)(x3)\n",
    "\n",
    "        # Skip connection 2\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a final layer normalization\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    # Create a global average pooling layer\n",
    "    representation = layers.GlobalAveragePooling1D()(representation)\n",
    "\n",
    "    # MLP head for classification\n",
    "    for units in mlp_units:\n",
    "        representation = layers.Dense(units, activation=tf.nn.gelu)(representation)\n",
    "        representation = layers.Dropout(0.1)(representation)\n",
    "\n",
    "    # Create the final output layer\n",
    "    logits = layers.Dense(num_classes)(representation)\n",
    "\n",
    "    # Create the Keras model\n",
    "    model = models.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c80c8b7-8925-4b16-ab3a-44c7511b20e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFICAYAAAAyFGczAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEOElEQVR4nO3bsQ2EQAwAQQ7Rf8umALTSJfwTzMQOHK2ceM3MHAA8nP9eAOCrBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEK7dwbXWm3sA/MzuA6ELEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgHDtDs7Mm3sAfI4LEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIg3AA6DI3YutA5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAFICAYAAADd1gwNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFOElEQVR4nO3bMaojQRAFwepF979yryXvk4wjpowIu41nJQUanXvvHQD+9O/tAQCbiSRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIHyePjzn/HLHI/XnoM37Nm+b2b1v87aZ3fs2b5vZv+/LJQkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECOfee98eAbCVSxIgiCRAEEmAIJIAQSQBwufpw3POL3c8Uj/Eb963edvM7n2bt83s3rd528z+fV8uSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAOPfe+/YIgK1ckgBBJAGCSAIEkQQIIgkQRBIgfJ4+POf8cscj9bXS5n2bt83s3rd528zufZu3zezf9+WSBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAHCuffet0cAbOWSBAgiCRBEEiCIJEAQSYAgkgDh8/ThOeeXOx6pr5U279u8bWb3vs3bZnbv27xtZv++L5ckQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCce+99ewTAVi5JgCCSAEEkAYJIAgSRBAifpw/POb/c8Uj9EL953+ZtM7v3bd42s3vf5m0z+/d9uSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAOHce+/bIwC2ckkCBJEECCIJEEQSIIgkQBBJgPB5+vCc88sdj9TXSpv3bd42s3vf5m0zu/dt3jazf9+XSxIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECOfee98eAbCVSxIgiCRAEEmAIJIAQSQBgkgChM/Th+ecX+54pL5W2rxv87aZ3fs2b5vZvW/ztpn9+75ckgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAcO699+0RAFu5JAGCSAIEkQQIIgkQRBIgfJ4+POf8cscj9UP85n2bt83s3rd528zufZu3zezf9+WSBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAKEc++9b48A2MolCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQ/gOgquZ0cF6KYQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x400 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize patches\n",
    "image_size = 32\n",
    "patch_size = 4\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(x_train.shape[0])]\n",
    "plt.imshow(image.astype('uint8'))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(tf.convert_to_tensor([image]), size=(image_size, image_size))\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype('uint8'))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79b24d2a-7499-4462-88d2-b38f6da9118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, x_train, y_train, x_test, y_test, batch_size, num_epochs, learning_rate, weight_decay):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.1)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Define hyperparameters\n",
    "num_epochs = 40\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee8cbbfb-0e33-4493-8b03-5d3ab0a0e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 446ms/step - accuracy: 0.2013 - loss: 2.0685 - val_accuracy: 0.3004 - val_loss: 1.8408\n",
      "Epoch 2/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 451ms/step - accuracy: 0.3321 - loss: 1.7161 - val_accuracy: 0.4100 - val_loss: 1.5503\n",
      "Epoch 3/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 448ms/step - accuracy: 0.4193 - loss: 1.5519 - val_accuracy: 0.4590 - val_loss: 1.4502\n",
      "Epoch 4/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 440ms/step - accuracy: 0.4659 - loss: 1.4450 - val_accuracy: 0.4744 - val_loss: 1.4095\n",
      "Epoch 5/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 439ms/step - accuracy: 0.5014 - loss: 1.3629 - val_accuracy: 0.5028 - val_loss: 1.3314\n",
      "Epoch 6/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 449ms/step - accuracy: 0.5234 - loss: 1.3056 - val_accuracy: 0.5280 - val_loss: 1.2877\n",
      "Epoch 7/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 442ms/step - accuracy: 0.5394 - loss: 1.2656 - val_accuracy: 0.5638 - val_loss: 1.2049\n",
      "Epoch 8/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 445ms/step - accuracy: 0.5592 - loss: 1.2145 - val_accuracy: 0.5604 - val_loss: 1.2035\n",
      "Epoch 9/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 447ms/step - accuracy: 0.5748 - loss: 1.1801 - val_accuracy: 0.5726 - val_loss: 1.1844\n",
      "Epoch 10/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 443ms/step - accuracy: 0.5915 - loss: 1.1381 - val_accuracy: 0.5986 - val_loss: 1.1162\n",
      "Epoch 11/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 470ms/step - accuracy: 0.6011 - loss: 1.1153 - val_accuracy: 0.5892 - val_loss: 1.1284\n",
      "Epoch 12/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 460ms/step - accuracy: 0.6162 - loss: 1.0775 - val_accuracy: 0.5868 - val_loss: 1.1243\n",
      "Epoch 13/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 457ms/step - accuracy: 0.6231 - loss: 1.0520 - val_accuracy: 0.6108 - val_loss: 1.1129\n",
      "Epoch 14/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 451ms/step - accuracy: 0.6296 - loss: 1.0258 - val_accuracy: 0.6162 - val_loss: 1.0848\n",
      "Epoch 15/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 445ms/step - accuracy: 0.6441 - loss: 0.9975 - val_accuracy: 0.6240 - val_loss: 1.0531\n",
      "Epoch 16/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 446ms/step - accuracy: 0.6546 - loss: 0.9672 - val_accuracy: 0.6298 - val_loss: 1.0585\n",
      "Epoch 17/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 445ms/step - accuracy: 0.6642 - loss: 0.9438 - val_accuracy: 0.6018 - val_loss: 1.1056\n",
      "Epoch 18/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 453ms/step - accuracy: 0.6725 - loss: 0.9187 - val_accuracy: 0.6276 - val_loss: 1.0612\n",
      "Epoch 19/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 444ms/step - accuracy: 0.6780 - loss: 0.9042 - val_accuracy: 0.6310 - val_loss: 1.0488\n",
      "Epoch 20/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 445ms/step - accuracy: 0.6867 - loss: 0.8740 - val_accuracy: 0.6440 - val_loss: 1.0077\n",
      "Epoch 21/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 524ms/step - accuracy: 0.6936 - loss: 0.8598 - val_accuracy: 0.6368 - val_loss: 1.0146\n",
      "Epoch 22/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 467ms/step - accuracy: 0.6991 - loss: 0.8346 - val_accuracy: 0.6416 - val_loss: 1.0196\n",
      "Epoch 23/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m821s\u001b[0m 584ms/step - accuracy: 0.7035 - loss: 0.8177 - val_accuracy: 0.6188 - val_loss: 1.0973\n",
      "Epoch 24/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m813s\u001b[0m 549ms/step - accuracy: 0.7178 - loss: 0.7926 - val_accuracy: 0.6358 - val_loss: 1.0475\n",
      "Epoch 25/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m795s\u001b[0m 544ms/step - accuracy: 0.7206 - loss: 0.7728 - val_accuracy: 0.6236 - val_loss: 1.1161\n",
      "Epoch 26/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m805s\u001b[0m 546ms/step - accuracy: 0.7307 - loss: 0.7464 - val_accuracy: 0.6560 - val_loss: 1.0266\n",
      "Epoch 27/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m697s\u001b[0m 496ms/step - accuracy: 0.7392 - loss: 0.7280 - val_accuracy: 0.6506 - val_loss: 1.0205\n",
      "Epoch 28/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 515ms/step - accuracy: 0.7455 - loss: 0.7088 - val_accuracy: 0.6332 - val_loss: 1.1077\n",
      "Epoch 29/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 469ms/step - accuracy: 0.7502 - loss: 0.6878 - val_accuracy: 0.6454 - val_loss: 1.0563\n",
      "Epoch 30/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m790s\u001b[0m 561ms/step - accuracy: 0.7562 - loss: 0.6644 - val_accuracy: 0.6456 - val_loss: 1.0679\n",
      "Epoch 31/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 513ms/step - accuracy: 0.7653 - loss: 0.6459 - val_accuracy: 0.6432 - val_loss: 1.0804\n",
      "Epoch 32/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 463ms/step - accuracy: 0.7729 - loss: 0.6312 - val_accuracy: 0.6604 - val_loss: 1.0418\n",
      "Epoch 33/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 453ms/step - accuracy: 0.7781 - loss: 0.6170 - val_accuracy: 0.6498 - val_loss: 1.0759\n",
      "Epoch 34/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 452ms/step - accuracy: 0.7897 - loss: 0.5883 - val_accuracy: 0.6488 - val_loss: 1.1329\n",
      "Epoch 35/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 448ms/step - accuracy: 0.7906 - loss: 0.5685 - val_accuracy: 0.6426 - val_loss: 1.1099\n",
      "Epoch 36/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 457ms/step - accuracy: 0.7934 - loss: 0.5685 - val_accuracy: 0.6396 - val_loss: 1.1575\n",
      "Epoch 37/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 456ms/step - accuracy: 0.7956 - loss: 0.5531 - val_accuracy: 0.6376 - val_loss: 1.1962\n",
      "Epoch 38/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m641s\u001b[0m 456ms/step - accuracy: 0.8108 - loss: 0.5279 - val_accuracy: 0.6472 - val_loss: 1.1723\n",
      "Epoch 39/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 453ms/step - accuracy: 0.8135 - loss: 0.5151 - val_accuracy: 0.6472 - val_loss: 1.1322\n",
      "Epoch 40/40\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 451ms/step - accuracy: 0.8166 - loss: 0.4982 - val_accuracy: 0.6418 - val_loss: 1.2181\n",
      "{'accuracy': [0.25235554575920105, 0.3586222231388092, 0.43026667833328247, 0.4733777642250061, 0.5032666921615601, 0.526711106300354, 0.5428444147109985, 0.5615333318710327, 0.5732222199440002, 0.5881999731063843, 0.5983777642250061, 0.6112444400787354, 0.6209777593612671, 0.6291999816894531, 0.6404666900634766, 0.6481333374977112, 0.6563777923583984, 0.6649777889251709, 0.6735777854919434, 0.6809555292129517, 0.6894444227218628, 0.6955999732017517, 0.7004666924476624, 0.7107999920845032, 0.716866672039032, 0.7225777506828308, 0.734155535697937, 0.7353333234786987, 0.7408000230789185, 0.7494444251060486, 0.755911111831665, 0.7624666690826416, 0.7703777551651001, 0.7757777571678162, 0.7813110947608948, 0.7873333096504211, 0.7919333577156067, 0.8008444309234619, 0.8053110837936401, 0.8086000084877014], 'loss': [1.9116212129592896, 1.6675670146942139, 1.5257800817489624, 1.4257233142852783, 1.3546613454818726, 1.301365613937378, 1.258452296257019, 1.2153866291046143, 1.1799124479293823, 1.1453412771224976, 1.1196858882904053, 1.0856205224990845, 1.05910325050354, 1.034315586090088, 1.00485098361969, 0.985107958316803, 0.9625545740127563, 0.9362702965736389, 0.9152550101280212, 0.8918007016181946, 0.8712964653968811, 0.8484519720077515, 0.8327496647834778, 0.8083996772766113, 0.7868470549583435, 0.7669045329093933, 0.7434381246566772, 0.7295385599136353, 0.7134534120559692, 0.6894208192825317, 0.6703369617462158, 0.6557326912879944, 0.6346443295478821, 0.6189139485359192, 0.5974414348602295, 0.5847334265708923, 0.568612813949585, 0.549797773361206, 0.5354750752449036, 0.522003173828125], 'val_accuracy': [0.3003999888896942, 0.4099999964237213, 0.45899999141693115, 0.47440001368522644, 0.5027999877929688, 0.527999997138977, 0.5637999773025513, 0.5604000091552734, 0.5726000070571899, 0.5985999703407288, 0.5892000198364258, 0.5867999792098999, 0.61080002784729, 0.6161999702453613, 0.6240000128746033, 0.629800021648407, 0.6018000245094299, 0.6276000142097473, 0.6309999823570251, 0.6439999938011169, 0.6367999911308289, 0.6416000127792358, 0.6187999844551086, 0.6358000040054321, 0.6236000061035156, 0.656000018119812, 0.650600016117096, 0.6331999897956848, 0.6453999876976013, 0.6456000208854675, 0.6431999802589417, 0.6603999733924866, 0.6498000025749207, 0.6488000154495239, 0.6425999999046326, 0.6395999789237976, 0.6376000046730042, 0.6471999883651733, 0.6471999883651733, 0.6417999863624573], 'val_loss': [1.8407697677612305, 1.5502930879592896, 1.450226902961731, 1.4094570875167847, 1.331360936164856, 1.2876529693603516, 1.2049049139022827, 1.2034839391708374, 1.1844276189804077, 1.1162495613098145, 1.1283806562423706, 1.1243191957473755, 1.1129440069198608, 1.0848342180252075, 1.0530661344528198, 1.0584795475006104, 1.1056288480758667, 1.0611803531646729, 1.0487710237503052, 1.0076874494552612, 1.0145847797393799, 1.019639015197754, 1.0972836017608643, 1.0474820137023926, 1.116128921508789, 1.0265997648239136, 1.0204657316207886, 1.1077486276626587, 1.0562565326690674, 1.0678842067718506, 1.0803519487380981, 1.0417988300323486, 1.075882077217102, 1.1328563690185547, 1.1099262237548828, 1.1574903726577759, 1.1962344646453857, 1.1723324060440063, 1.1321570873260498, 1.2181499004364014]}\n"
     ]
    }
   ],
   "source": [
    "# Create the Vision Transformer classifier\n",
    "vit_classifier = create_vit_classifier()\n",
    "\n",
    "# Run the experiment\n",
    "history = run_experiment(vit_classifier, x_train, y_train, x_test, y_test, batch_size, num_epochs, learning_rate, weight_decay)\n",
    "\n",
    "# Check the history object to see the training results\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824896d6-0059-42d9-8dc4-ebd5bd65c317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
